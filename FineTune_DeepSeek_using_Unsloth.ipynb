{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jKcyLUS8jKkdR0_cikPJA0TShh1jDa-O",
      "authorship_tag": "ABX9TyOQm1IwX3WxQOrOE8cV57n9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakshitshah280701/InstructAware/blob/main/Option4_Training_DeepSeek_using_Unsloth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nyiee1LtLbIV"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip uninstall unsloth -y\n",
        "!pip install unsloth[colab-new]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers datasets huggingface_hub\n"
      ],
      "metadata": {
        "id": "cHaVbCQDNu-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from unsloth import FastLanguageModel\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "aLcrAF3KQY--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get(\"DeepSeek\")  # Correct retrieval method\n",
        "\n",
        "if hf_token is None:\n",
        "    raise ValueError(\"Hugging Face token not found in Colab secrets. Make sure you added it correctly.\")\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token=hf_token)\n"
      ],
      "metadata": {
        "id": "ZIN0522I3cU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token,\n",
        ")"
      ],
      "metadata": {
        "id": "4yw_LTs23Ue8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re  # Import regex for text cleaning\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Add EOS_TOKEN at the end of each entry\n",
        "\n",
        "\n",
        "# Load cleaned CSVs\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/InstructAware/REU/OpenAI/Data/InstructAware/CSV/train_dataset_cleaned.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/InstructAware/REU/OpenAI/Data/InstructAware/CSV/validation_dataset_cleaned.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/InstructAware/REU/OpenAI/Data/InstructAware/CSV/test_dataset_cleaned.csv\")\n",
        "\n",
        "# Format to prompt-response style\n",
        "def format_prompt_response(df):\n",
        "    texts = []\n",
        "    for i, row in df.iterrows():\n",
        "        input_text = row[\"INPUT TEXT\"]\n",
        "        output_text = row[\"OUTPUT TEXT\"]\n",
        "        full_text = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the details and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are an AI vision assistant with advanced capabilities that help people with low vision to understand their surroundings by providing them natural language narratives based on detected signs, bounding box coordinates, and OCR text.\n",
        "\n",
        "### Detected Text & Locations:\n",
        "{input_text}\n",
        "\n",
        "### Response:\n",
        "<think>{output_text}</think>{EOS_TOKEN}\n",
        "\"\"\"\n",
        "        texts.append(full_text)\n",
        "    return Dataset.from_dict({\"text\": texts})\n",
        "\n",
        "# Convert to HF Dataset\n",
        "train_dataset = format_prompt_response(train_df)\n",
        "val_dataset = format_prompt_response(val_df)\n",
        "test_dataset = format_prompt_response(test_df)\n",
        "\n",
        "# Combine into a dataset dict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"validation\": val_dataset,\n",
        "    \"test\": test_dataset,\n",
        "})\n",
        "\n",
        "# Save to disk\n",
        "dataset.save_to_disk(\"/content/structured_split_dataset\")\n"
      ],
      "metadata": {
        "id": "p5IOF9mt0jAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "dataset_path = \"/content/structured_split_dataset\"\n",
        "dataset = load_from_disk(dataset_path)\n"
      ],
      "metadata": {
        "id": "dP5z8Hhh1imK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/InstructAware/Code/Option4TransformerDeepSeek/Deepseek_Logs\"\n"
      ],
      "metadata": {
        "id": "1yu2ZpVssASb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments\n",
        "# from unsloth import is_bfloat16_supported\n",
        "\n",
        "# trainer = SFTTrainer(\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     train_dataset=dataset[\"train\"],\n",
        "#     eval_dataset=dataset[\"validation\"],\n",
        "#     dataset_text_field=\"text\",\n",
        "#     max_seq_length=max_seq_length,\n",
        "#     dataset_num_proc=2,\n",
        "#     args=TrainingArguments(\n",
        "#         per_device_train_batch_size=2,\n",
        "#         gradient_accumulation_steps=4,\n",
        "#         warmup_steps=5,\n",
        "#         max_steps=60,\n",
        "#         learning_rate=2e-4,\n",
        "#         fp16=not is_bfloat16_supported(),\n",
        "#         bf16=is_bfloat16_supported(),\n",
        "#         logging_steps=10,\n",
        "#         evaluation_strategy=\"steps\",\n",
        "#         eval_steps=20,\n",
        "#         save_strategy=\"no\",\n",
        "#         optim=\"adamw_8bit\",\n",
        "#         weight_decay=0.01,\n",
        "#         lr_scheduler_type=\"linear\",\n",
        "#         seed=3407,\n",
        "#         output_dir=\"outputs\",\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "# trainer_stats = trainer.train()\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_dir=output_dir,                     # ‚úÖ log dir for TensorBoard\n",
        "        logging_steps=10,                           # ‚úÖ how often to log\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=20,\n",
        "        save_strategy=\"no\",\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=output_dir,                      # ‚úÖ saves checkpoints & logs\n",
        "        report_to=\"tensorboard\",                    # ‚úÖ enable TensorBoard logging\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()\n"
      ],
      "metadata": {
        "id": "g4XwVbLPvh1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/InstructAware/Code/Option4TransformerDeepSeek/Deepseek_Logs\n"
      ],
      "metadata": {
        "id": "k1B0sCJd_cTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Example inference loop over test data\n",
        "for i in range(3):  # Change to len(dataset[\"test\"]) for full\n",
        "    test_prompt = dataset[\"test\"][i][\"text\"].split(\"### Response:\")[0] + \"### Response:\\n\"\n",
        "\n",
        "    inputs = tokenizer([test_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_new_tokens=1200,\n",
        "        use_cache=True,\n",
        "    )\n",
        "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    print(f\"üîç Prediction {i+1}:\\n\", response.split(\"### Response:\")[1].strip())\n",
        "    print(\"‚îÄ\" * 100)\n"
      ],
      "metadata": {
        "id": "KNZBF1VT5uAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_path = \"/content/drive/MyDrive/InstructAware/Code/Option4TransformerDeepSeek/7thAprilRun\"\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(save_model_path)\n",
        "tokenizer.save_pretrained(save_model_path)\n",
        "\n",
        "print(f\"‚úÖ Model and tokenizer saved at: {save_model_path}\")\n"
      ],
      "metadata": {
        "id": "bfcWVG7q-Ipo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Load original test data with ground truth\n",
        "test_df_raw = pd.read_csv(\"/content/drive/MyDrive/InstructAware/REU/OpenAI/Data/InstructAware/CSV/test_dataset_cleaned.csv\")\n",
        "\n",
        "# Ensure same length & order\n",
        "assert len(test_df_raw) == len(dataset[\"test\"])\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for i in tqdm(range(len(dataset[\"test\"]))):\n",
        "    example = dataset[\"test\"][i][\"text\"]\n",
        "    prompt = example.split(\"### Response:\")[0] + \"### Response:\\n\"\n",
        "\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_new_tokens=1200,\n",
        "        use_cache=True,\n",
        "    )\n",
        "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    response_clean = response.split(\"### Response:\")[1].strip() if \"### Response:\" in response else response\n",
        "\n",
        "    predictions.append({\n",
        "        \"INPUT TEXT\": test_df_raw.iloc[i][\"INPUT TEXT\"],\n",
        "        \"ORIGINAL OUTPUT TEXT\": test_df_raw.iloc[i][\"OUTPUT TEXT\"],\n",
        "        \"PREDICTED OUTPUT TEXT\": response_clean\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "pred_df = pd.DataFrame(predictions)\n",
        "\n",
        "# Save to CSV\n",
        "output_csv_path = \"/content/drive/MyDrive/InstructAware/Code/Option4TransformerDeepSeek/7thAprilRun/Output.csv\"\n",
        "pred_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Predictions with ground truth saved to: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "gxrqylVw4npR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "csv_path = \"/content/drive/MyDrive/InstructAware/Code/Option4TransformerDeepSeek/7thAprilRun/Output.csv\"  # Update the path if needed\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Display first few rows\n",
        "df.head()\n",
        "\n",
        "from google.colab import data_table\n",
        "\n",
        "# Display CSV as an interactive table\n",
        "data_table.DataTable(df)"
      ],
      "metadata": {
        "id": "xJK9NCTH4-aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OEdYJM9M9cHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
